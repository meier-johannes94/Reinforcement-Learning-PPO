{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'env' referenced before assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ca13bf3ea588>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Train report settings\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m train_register_change(DEFAULT_max_training_episodes, DEFAULT_training_length, DEFAULT_eval_length, DEFAULT_max_timesteps_per_episode,\n\u001b[0m\u001b[0;32m     63\u001b[0m                       \u001b[0mDEFAULT_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_K_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_eps_clip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_eps_value_clip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_policy_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_policy_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_value_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_value_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_activation_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                       \u001b[0mDEFAULT_initializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_policy_last_layer_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_value_last_layer_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_minimum_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Johannes\\Desktop\\Modify\\Reinforcement-Learning-PPO\\main.py\u001b[0m in \u001b[0;36mtrain_register_change\u001b[1;34m(training_episodes, training_length, eval_length, max_timesteps_per_episode, gamma, K_epochs, eps_clip, eps_value_clip, policy_depth, policy_width, value_depth, value_width, activation_function, initializer, policy_last_layer_scaler, value_last_layer_scaler, minimum_std, initial_std, handle_abandoned, reward_normalization, mini_batch_size, batch_mode, optimizer_lr, optimizer_weight_decay, optimizer_momentum, optimizer_epsilon, frame_skipping_length, value_normalization, advantage_normalization, input_normalization, update_episodes, save_episodes, opponent_type, opponent_weak, default_timestep_loss, frame_skip_frequency, input_clipping_max_abs_value, gradient_clipping, lbda, filename, seed, load_filename, print_config, load_info)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'env' referenced before assignment"
     ]
    }
   ],
   "source": [
    "    %load_ext autoreload\n",
    "\n",
    "    %autoreload 2\n",
    "\n",
    "    import os\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "    from main import train_register_change\n",
    "    from PPO import ActivationFunctions, Initializers, BatchModes\n",
    "    from Agent import OpponentType\n",
    "\n",
    "    DEFAULT_policy_depth = 2\n",
    "    DEFAULT_policy_width = 128\n",
    "    DEFAULT_value_depth = 4\n",
    "    DEFAULT_value_width = 256\n",
    "    DEFAULT_activation_function = ActivationFunctions.Tanh  # TESTING\n",
    "    DEFAULT_initializer = Initializers.Orthogonal\n",
    "    DEFAULT_value_last_layer_scaler = 0.001\n",
    "    DEFAULT_policy_last_layer_scaler = 0.01\n",
    "    DEFAULT_minimum_std = 0.01\n",
    "    DEFAULT_initial_std = 0.5\n",
    "\n",
    "    DEFAULT_input_clipping_max_abs_value = 10\n",
    "    DEFAULT_gradient_clipping = 10\n",
    "    DEFAULT_reward_normalizations = False\n",
    "    DEFAULT_value_normalization = False\n",
    "    DEFAULT_advantage_normalization = False\n",
    "    DEFAULT_input_normalization = True\n",
    "\n",
    "    DEFAULT_gamma = 0.95\n",
    "    DEFAULT_handle_abandoned = True\n",
    "    DEFAULT_frame_skipping = 1\n",
    "    DEFAULT_frame_skip_interval = None\n",
    "\n",
    "    DEFAULT_lbda = 0.95\n",
    "    DEFAULT_eps_value_clip = None\n",
    "\n",
    "    DEFAULT_eps_clip = 0.25\n",
    "    DEFAULT_K_epochs = 10\n",
    "    DEFAULT_mini_batch_size = 128\n",
    "    DEFAULT_batch_mode = Batch_Mode.Shuffle_Transitions_Recompute_Advantages\n",
    "    DEFAULT_update_episodes = 20000\n",
    "\n",
    "    DEFAULT_optimizer_lrs = 0.0003\n",
    "    DEFAULT_optimizer_weight_decay = 0.0\n",
    "    DEFAULT_optimizer_momentum = 0.9\n",
    "    DEFAULT_optimizer_epsilon = 1e-8\n",
    "\n",
    "    DEFAULT_training_length = 10\n",
    "    DEFAULT_eval_length = 4\n",
    "    DEFAULT_max_timesteps_per_episode = 402\n",
    "    DEFAULT_save_episode = DEFAULT_training_length + DEFAULT_eval_length\n",
    "\n",
    "    DEFAULT_opponent_type = Opponent_Type.Normal\n",
    "    DEFAULT_opponent_weak = False\n",
    "    DEFAULT_timestep_loss = 0\n",
    "\n",
    "    DEFAULT_max_training_episodes = 40000\n",
    "\n",
    "    seed_1 = 123456\n",
    "    title = save_filename = \"Train report settings\"\n",
    "\n",
    "    train_register_change(DEFAULT_max_training_episodes, DEFAULT_training_length, DEFAULT_eval_length, DEFAULT_max_timesteps_per_episode,\n",
    "                          DEFAULT_gamma, DEFAULT_K_epochs, DEFAULT_eps_clip, DEFAULT_eps_value_clip, DEFAULT_policy_depth, DEFAULT_policy_width, DEFAULT_value_depth, DEFAULT_value_width, DEFAULT_activation_function,\n",
    "                          DEFAULT_initializer, DEFAULT_policy_last_layer_scaler, DEFAULT_value_last_layer_scaler, DEFAULT_minimum_std,\n",
    "                          DEFAULT_initial_std, DEFAULT_handle_abandoned, DEFAULT_reward_normalizations, DEFAULT_mini_batch_size, DEFAULT_batch_mode, DEFAULT_optimizer_lrs,\n",
    "                          DEFAULT_optimizer_weight_decay, DEFAULT_optimizer_momentum, DEFAULT_optimizer_epsilon, DEFAULT_frame_skipping, DEFAULT_value_normalization, DEFAULT_advantage_normalization,\n",
    "                          DEFAULT_input_normalization, DEFAULT_update_episodes, DEFAULT_save_episode, DEFAULT_opponent_type,\n",
    "                          DEFAULT_opponent_weak, DEFAULT_timestep_loss, DEFAULT_frame_skip_interval,\n",
    "                          DEFAULT_input_clipping_max_abs_value, DEFAULT_gradient_clipping, DEFAULT_lbda, save_filename, seed_1, print_config=False, load_info=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "asdfs 3.33 df\n3.334\n"
     ]
    }
   ],
   "source": [
    "d = 3.3344\n",
    "print(f\"asdfs {d:2.02f} df\")\n",
    "print(\"{:.3f}\".format(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.3 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "951b67a811c67cbb407e4a19bf29e038a158d4ed31c2fea63332fa350584f881"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}